{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlxspl8GGpaYvMBwMDCv28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SajalGarg035/machine-learning-data-science/blob/main/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dffUFMcH6qJ6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zemFTSNH63fF",
        "outputId": "99fb23b0-47ca-44ad-dca6-6cd8fe0b3f14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = fashion\n",
        "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
        "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
      ],
      "metadata": {
        "id": "SST_GlFP66Ku"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(\"\\n\")\n",
        "X_train.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU-4EXuf7Gvd",
        "outputId": "1479400f-8169-4112-d691-956b30daf3a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55000, 28, 28)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we’ll scale the pixel intensities down to the 0–1 range by dividing them\n",
        "by **255.0** *`italicized text`*"
      ],
      "metadata": {
        "id": "Czt9eSZg7ZeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255."
      ],
      "metadata": {
        "id": "GngR7W_17Te5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TcZszao-8qCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You could also choose to use the tf.keras.utils.set_ran\n",
        "dom_seed() function, which conveniently sets the random seeds for TensorFlow,\n",
        "Python (random.seed()), and NumPy (np.random.seed()).\n",
        "\n"
      ],
      "metadata": {
        "id": "oTBi4qIJ8qRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=[28, 28]))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(300, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "Xl7glSIz8GWj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.Sequential([\n",
        "# tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "# tf.keras.layers.Dense(300, activation=\"relu\"),\n",
        "# tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "# tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "# ])\n",
        "# 320\n",
        "\n",
        "#alternative we can use this too\n"
      ],
      "metadata": {
        "id": "LvetxpM28yiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*The model’s summary() method displays all the model’s layers,14 including each layer’s*\n"
      ],
      "metadata": {
        "id": "0PSNeCdw8831"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pz_LMRd822I",
        "outputId": "e9f0c1e3-fd3f-4be4-f987-cac55ce14849"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               30100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266610 (1.02 MB)\n",
            "Trainable params: 266610 (1.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLRJshhW9EDn",
        "outputId": "db55c13d-2854-4805-b768-749c09db2b4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.src.layers.reshaping.flatten.Flatten at 0x7cf32f3a3370>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7cf322c2b550>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7cf322b0c580>,\n",
              " <keras.src.layers.core.dense.Dense at 0x7cf322b0c670>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_layer('dense')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUCo9lHp9EM6",
        "outputId": "fedc88c6-12fd-4c9e-8846-b8a40f30d9bc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.dense.Dense at 0x7cf322c2b550>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kHH_9Kq59kED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After a model is created, you must call its compile() method to specify the loss\n",
        "function and the optimizer to use. Optionally, you can specify a list of extra metrics to\n",
        "compute during training and evaluation"
      ],
      "metadata": {
        "id": "MlNG6aQL9lpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "optimizer=\"sgd\",\n",
        "metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "dVQHK1Us9c5t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss=\"sparse_categorical_crossentropy\" is the equivalent\n",
        "of using loss=tf.keras.losses.sparse_categorical_\n",
        "crossentropy. Similarly, using optimizer=\"sgd\" is the equivalent\n",
        "of using optimizer=tf.keras.optimizers.SGD(), and using\n",
        "metrics=[\"accuracy\"] is the equivalent of using metrics=\n",
        "[tf.keras.metrics.sparse_categorical_accuracy] (when using\n",
        "this loss).\n",
        "\n",
        "\n",
        "\n",
        "We use the \"sparse_categorical_crossentropy\"\n",
        "loss because we have sparse labels (i.e., for each instance, there is just a target class\n",
        "index, from 0 to 9 in this case), and the classes are exclusive. If instead we had\n",
        "one target probability per class for each instance (such as one-hot vectors, e.g.,\n",
        "[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would\n",
        "need to use the \"categorical_crossentropy\" loss instead. If we were doing binary\n",
        "classification or multilabel binary classification, then we would use the \"sigmoid\"\n",
        "activation function in the output layer instead of the \"softmax\" activation function,\n",
        "and we would use the \"binary_crossentropy\" loss."
      ],
      "metadata": {
        "id": "JbPox_z89sTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV85cDSb93su",
        "outputId": "09adfe58-f063-44b3-e2a3-36822bbd56e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7321 - accuracy: 0.7597 - val_loss: 0.5142 - val_accuracy: 0.8280\n",
            "Epoch 2/30\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4931 - accuracy: 0.8297 - val_loss: 0.4656 - val_accuracy: 0.8322\n",
            "Epoch 3/30\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4461 - accuracy: 0.8449 - val_loss: 0.4295 - val_accuracy: 0.8516\n",
            "Epoch 4/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4212 - accuracy: 0.8530 - val_loss: 0.4014 - val_accuracy: 0.8584\n",
            "Epoch 5/30\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4001 - accuracy: 0.8600 - val_loss: 0.3942 - val_accuracy: 0.8602\n",
            "Epoch 6/30\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3832 - accuracy: 0.8652 - val_loss: 0.3987 - val_accuracy: 0.8632\n",
            "Epoch 7/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3706 - accuracy: 0.8688 - val_loss: 0.3778 - val_accuracy: 0.8676\n",
            "Epoch 8/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3588 - accuracy: 0.8740 - val_loss: 0.3706 - val_accuracy: 0.8674\n",
            "Epoch 9/30\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3474 - accuracy: 0.8772 - val_loss: 0.3537 - val_accuracy: 0.8730\n",
            "Epoch 10/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3378 - accuracy: 0.8795 - val_loss: 0.3559 - val_accuracy: 0.8724\n",
            "Epoch 11/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3288 - accuracy: 0.8832 - val_loss: 0.3669 - val_accuracy: 0.8668\n",
            "Epoch 12/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3210 - accuracy: 0.8839 - val_loss: 0.3508 - val_accuracy: 0.8698\n",
            "Epoch 13/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.3135 - accuracy: 0.8887 - val_loss: 0.3344 - val_accuracy: 0.8760\n",
            "Epoch 14/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3063 - accuracy: 0.8896 - val_loss: 0.3459 - val_accuracy: 0.8744\n",
            "Epoch 15/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3005 - accuracy: 0.8933 - val_loss: 0.3393 - val_accuracy: 0.8776\n",
            "Epoch 16/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2932 - accuracy: 0.8951 - val_loss: 0.3350 - val_accuracy: 0.8780\n",
            "Epoch 17/30\n",
            "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2879 - accuracy: 0.8961 - val_loss: 0.3371 - val_accuracy: 0.8754\n",
            "Epoch 18/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2825 - accuracy: 0.8979 - val_loss: 0.3296 - val_accuracy: 0.8798\n",
            "Epoch 19/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2770 - accuracy: 0.8993 - val_loss: 0.3527 - val_accuracy: 0.8682\n",
            "Epoch 20/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2723 - accuracy: 0.9017 - val_loss: 0.3239 - val_accuracy: 0.8812\n",
            "Epoch 21/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2670 - accuracy: 0.9028 - val_loss: 0.3176 - val_accuracy: 0.8834\n",
            "Epoch 22/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2617 - accuracy: 0.9051 - val_loss: 0.3169 - val_accuracy: 0.8850\n",
            "Epoch 23/30\n",
            "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2574 - accuracy: 0.9075 - val_loss: 0.3469 - val_accuracy: 0.8736\n",
            "Epoch 24/30\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2523 - accuracy: 0.9080 - val_loss: 0.3270 - val_accuracy: 0.8816\n",
            "Epoch 25/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2477 - accuracy: 0.9100 - val_loss: 0.3227 - val_accuracy: 0.8808\n",
            "Epoch 26/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2445 - accuracy: 0.9122 - val_loss: 0.3152 - val_accuracy: 0.8872\n",
            "Epoch 27/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2392 - accuracy: 0.9137 - val_loss: 0.3247 - val_accuracy: 0.8836\n",
            "Epoch 28/30\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2366 - accuracy: 0.9154 - val_loss: 0.3111 - val_accuracy: 0.8870\n",
            "Epoch 29/30\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2318 - accuracy: 0.9166 - val_loss: 0.3249 - val_accuracy: 0.8816\n",
            "Epoch 30/30\n",
            "1719/1719 [==============================] - 8s 5ms/step - loss: 0.2283 - accuracy: 0.9175 - val_loss: 0.3107 - val_accuracy: 0.8850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We pass it the input features (X_train) and the target classes (y_train), as well as the\n",
        "number of epochs to train (or else it would default to just 1, which would definitely\n",
        "not be enough to converge to a good solution). We also pass a validation set (this is\n",
        "optional). Keras will measure the loss and the extra metrics on this set at the end of\n",
        "each epoch, which is very useful to see how well the model really performs. If the\n",
        "performance on the training set is much better than on the validation set, your mod"
      ],
      "metadata": {
        "id": "4UkeHl1c-Ecl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If the\n",
        "# performance on the training set is much better than on the validation set, your model\n",
        "# is probably overfitting the training set, or there is a bug, such as a data mismatch\n",
        "# between the training set and the validation set."
      ],
      "metadata": {
        "id": "Fglh8MjG-FRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And that’s it! The neural network is trained. At each epoch during training, Keras\n",
        "# displays the number of mini-batches processed so far on the left side of the progress\n",
        "# bar. The batch size is 32 by default, and since the training set has 55,000 images, the\n",
        "# model goes through 1,719 batches per epoch: 1,718 of size 32, and 1 of size 24. After\n",
        "# the progress bar, you can see the mean training time per sample, and the loss and\n",
        "# accuracy (or any other extra metrics you asked for) on both the training set and the\n",
        "# validation set. Notice that the training loss went down, which is a good sign, and the\n",
        "# validation accuracy reached 88.94% after 30 epochs. That’s slightly below the training\n",
        "# accuracy, so there is a little bit of overfitting going on, but not a huge amount."
      ],
      "metadata": {
        "id": "aLitjKWV-Ube"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}